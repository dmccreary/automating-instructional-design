# Quiz: Anticipating Misconceptions

Test your understanding of mental models, common misconceptions, and design strategies for helping learners correct faulty beliefs.

---

#### 1. What is a mental model?

<div class="upper-alpha" markdown>
1. A 3D physical replica used for teaching
2. An internal representation of how things work that allows predictions and understanding
3. A mathematical equation describing system behavior
4. A diagram showing the relationships between concepts
</div>

??? question "Show Answer"
    The correct answer is **B**. A mental model is an internal representation of how things work—a personal simulation running in someone's head. When you ask "what happens if I drop this ball?", your mental model of gravity runs a quick simulation and predicts the outcome. Mental models can be accurate, partially accurate, or wildly wrong—and the person holding them often can't tell the difference.

    **Concept Tested:** Mental Model

    **See:** [Mental Models: The Invisible Architects of Understanding](#mental-models-the-invisible-architects-of-understanding)

---

#### 2. What distinguishes a misconception from simply "not knowing" something?

<div class="upper-alpha" markdown>
1. Misconceptions only occur in scientific subjects
2. A misconception is a mental model that conflicts with accepted understanding—"knowing something that isn't so"
3. Misconceptions are easier to correct than knowledge gaps
4. Misconceptions only develop in childhood
</div>

??? question "Show Answer"
    The correct answer is **B**. A misconception isn't just "not knowing"—it's "knowing something that isn't so." Misconceptions are particularly tricky because they often produce correct predictions in everyday situations, feel intuitively right, are resistant to simple correction, and can regenerate even after being "corrected."

    **Concept Tested:** Misconception

    **See:** [Misconceptions: When Mental Models Go Wrong](#misconceptions-when-mental-models-go-wrong)

---

#### 3. Why does simply telling learners the correct information usually fail to correct misconceptions?

<div class="upper-alpha" markdown>
1. Learners don't pay attention to verbal explanations
2. Misconceptions are stored in long-term memory with strong associations, and new information gets filtered through existing mental models
3. Verbal explanations are too complex for learners to understand
4. Learners prefer to discover information themselves
</div>

??? question "Show Answer"
    The correct answer is **B**. Research consistently shows that simply telling learners the correct information is ineffective because misconceptions are stored in long-term memory with strong associations, new information gets filtered through existing mental models, there's no cognitive conflict to motivate change, and verbal knowledge can coexist with incorrect intuitions without integration.

    **Concept Tested:** Misconception Correction

    **See:** [Why Simple Telling Doesn't Work](#why-simple-telling-doesnt-work)

---

#### 4. What are the four conditions necessary for conceptual change according to the theory developed by Posner et al.?

<div class="upper-alpha" markdown>
1. Motivation, practice, feedback, and repetition
2. Dissatisfaction, intelligibility, plausibility, and fruitfulness
3. Observation, hypothesis, experiment, and conclusion
4. Recognition, understanding, application, and analysis
</div>

??? question "Show Answer"
    The correct answer is **B**. Conceptual change requires: Dissatisfaction (the learner must be dissatisfied with their current conception), Intelligibility (the new conception must be understandable), Plausibility (the new conception must seem potentially true), and Fruitfulness (the new conception must be useful for solving problems). All four conditions must be met for conceptual change to occur.

    **Concept Tested:** Conceptual Change

    **See:** [Conceptual Change: The Deep Restructuring of Understanding](#conceptual-change-the-deep-restructuring-of-understanding)

---

#### 5. What is productive failure, and why does it work?

<div class="upper-alpha" markdown>
1. Failing repeatedly until giving up, which motivates seeking help
2. Deliberately allowing learners to struggle before receiving instruction, which activates prior knowledge and creates readiness for learning
3. Providing incorrect answers to test learner attention
4. Designing MicroSims that occasionally crash to test resilience
</div>

??? question "Show Answer"
    The correct answer is **B**. Productive failure is a learning design approach where learners are deliberately allowed to struggle with problems before receiving instruction. It works because the struggle activates prior knowledge, focuses attention on what's important to learn, creates gap awareness that motivates learning, produces deeper encoding when the solution arrives, and develops metacognition.

    **Concept Tested:** Productive Failure

    **See:** [Productive Failure: Embracing the Struggle](#productive-failure-embracing-the-struggle)

---

#### 6. What is the purpose of a prediction prompt in MicroSim design?

<div class="upper-alpha" markdown>
1. To test whether the MicroSim code is working correctly
2. To make learners commit to an expected outcome before observation, which activates beliefs and amplifies learning from surprises
3. To help the AI system understand what learners want
4. To predict how long learners will spend on the MicroSim
</div>

??? question "Show Answer"
    The correct answer is **B**. Prediction prompts ask learners to predict an outcome before observing it. This activates existing beliefs, creates commitment so learners are invested in the outcome, focuses attention, and amplifies surprise when wrong. Research shows prediction-then-observation produces better learning than observation alone—especially when predictions are wrong, as those are moments of productive cognitive conflict.

    **Concept Tested:** Prediction Prompt

    **See:** [Prediction Prompts: The Power of Commitment](#prediction-prompts-the-power-of-commitment)

---

#### 7. What is misconception reinforcement, and how might a MicroSim accidentally cause it?

<div class="upper-alpha" markdown>
1. Strengthening correct understanding through repetition
2. When instructional materials inadvertently confirm or entrench incorrect beliefs, such as through flawed analogies used without limits
3. Providing extra practice for struggling learners
4. Using positive reinforcement to encourage exploration
</div>

??? question "Show Answer"
    The correct answer is **B**. Misconception reinforcement occurs when instructional materials inadvertently confirm or entrench incorrect beliefs. MicroSims can cause this through using flawed analogies without explaining their limits, showing simplified visualizations that reinforce incorrect models, allowing misconception-consistent predictions without contradiction, and providing premature correct answers before learners grapple with why their intuition was wrong.

    **Concept Tested:** Misconception Reinforcement

    **See:** [Misconception Reinforcement: When Good Intentions Go Bad](#misconception-reinforcement-when-good-intentions-go-bad)

---

#### 8. What are conceptual boundaries in the context of mental models?

<div class="upper-alpha" markdown>
1. The physical borders of a diagram or visualization
2. The situations where a model applies and where it breaks down
3. The maximum number of concepts a learner can understand
4. The dividing lines between different academic subjects
</div>

??? question "Show Answer"
    The correct answer is **B**. Conceptual boundaries define the situations where a model applies and where it breaks down. Expert understanding includes knowing these boundaries. Novice misconceptions often result from over-applying a model beyond its valid range. For example, the "electricity is like water" analogy works for basic concepts but breaks down completely for inductance and AC behavior.

    **Concept Tested:** Conceptual Boundary

    **See:** [Conceptual Boundaries: Knowing the Limits of Models](#conceptual-boundaries-knowing-the-limits-of-models)

---

#### 9. What is the purpose of model comparison in addressing misconceptions?

<div class="upper-alpha" markdown>
1. To show learners that all models are equally valid
2. To present multiple models side by side so learners can compare their explanatory power and see where each succeeds or fails
3. To help learners choose their favorite model based on aesthetics
4. To demonstrate that science is always uncertain
</div>

??? question "Show Answer"
    The correct answer is **B**. Model comparison presents multiple mental models side by side, allowing learners to compare their explanatory power. This is more effective than teaching only the "correct" model because misconceptions are addressed rather than ignored, explanatory power becomes visible, conditions of applicability emerge naturally, and learners understand why the scientific model is genuinely better.

    **Concept Tested:** Model Comparison

    **See:** [Model Comparison: Side-by-Side Enlightenment](#model-comparison-side-by-side-enlightenment)

---

#### 10. In the PREDICT framework for designing misconception-targeting MicroSims, what does the "E" stand for?

<div class="upper-alpha" markdown>
1. Evaluate learner performance
2. Engineer cognitive conflict
3. Establish baseline knowledge
4. Explain the correct answer
</div>

??? question "Show Answer"
    The correct answer is **B**. In the PREDICT framework, E stands for "Engineer cognitive conflict." The full framework is: Probe existing beliefs, Require prediction, Engineer cognitive conflict (design scenarios where misconceptions fail visibly), Deliver the better model, Integrate through comparison, Consolidate with practice, and Track and respond to persistent misconceptions.

    **Concept Tested:** Misconception Correction

    **See:** [The PREDICT Framework](#the-predict-framework)

