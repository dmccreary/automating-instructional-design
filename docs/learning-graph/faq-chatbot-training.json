{
  "faq_version": "1.0",
  "generated_date": "2025-12-18",
  "source_textbook": "Automating Instructional Design",
  "total_questions": 67,
  "categories": {
    "getting_started": 12,
    "core_concepts": 16,
    "technical_details": 12,
    "common_challenges": 9,
    "best_practices": 10,
    "advanced_topics": 8
  },
  "bloom_distribution": {
    "remember": 12,
    "understand": 22,
    "apply": 18,
    "analyze": 9,
    "evaluate": 4,
    "create": 2
  },
  "questions": [
    {
      "id": "faq-001",
      "category": "Getting Started",
      "question": "What is this course about?",
      "answer": "This course teaches educators and training professionals how to transform learning objectives into interactive educational simulations called MicroSims using AI-assisted tools. You'll master the complete lifecycle of MicroSim development—from analyzing pedagogical goals through deployment and learner assessment—using Claude Code skills and visualization libraries.",
      "bloom_level": "Understand",
      "difficulty": "easy",
      "concepts": ["Instructional Design", "MicroSim", "AI-Assisted Design"],
      "keywords": ["course", "overview", "objectives", "MicroSim", "AI-assisted"],
      "source_links": ["docs/course-description.md", "docs/index.md"],
      "has_example": true,
      "word_count": 156
    },
    {
      "id": "faq-002",
      "category": "Getting Started",
      "question": "Who is this course designed for?",
      "answer": "This course is designed for working professionals who create educational content: K-12 teachers, corporate training specialists, higher education faculty, instructional designers, curriculum developers, and subject matter experts. No programming background is required.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Instructional Design", "Educational Technology"],
      "keywords": ["audience", "teachers", "designers", "prerequisites"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 89
    },
    {
      "id": "faq-003",
      "category": "Getting Started",
      "question": "What prerequisites do I need?",
      "answer": "You need only basic computer literacy—no programming experience required. The course teaches you to specify what simulations should do, not how to code them. You should be comfortable with using web browsers, writing clear descriptive text, and thinking systematically about learning goals.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Prerequisite Knowledge", "Assumed Knowledge"],
      "keywords": ["prerequisites", "requirements", "skills", "programming"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 78
    },
    {
      "id": "faq-004",
      "category": "Getting Started",
      "question": "How long does this course take to complete?",
      "answer": "The course offers two completion paths: Self-paced (60-80 hours total) or Instructor-led (3-4 hours per week for 12 weeks). Each module includes readings, hands-on activities, and a MicroSim project.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Instructional Design"],
      "keywords": ["duration", "time", "commitment", "weeks", "hours"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 62
    },
    {
      "id": "faq-005",
      "category": "Getting Started",
      "question": "What tools and software do I need?",
      "answer": "All required tools are provided: Claude Code with MicroSim generation skills, access to the MicroSim template library, and a modern web browser with developer tools.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Claude Code Skills", "Template Library", "Educational Technology"],
      "keywords": ["tools", "software", "Claude Code", "browser"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 54
    },
    {
      "id": "faq-006",
      "category": "Getting Started",
      "question": "How is this different from learning to code?",
      "answer": "This course explicitly does not teach programming. Instead, you learn to specify what simulations should look like and behave, evaluate whether generated simulations meet objectives, and iterate through refinement conversations with AI. The designer's role shifts from implementation to specification and quality assurance.",
      "bloom_level": "Understand",
      "difficulty": "easy",
      "concepts": ["AI-Assisted Design", "Specification Document", "Prompt Engineering"],
      "keywords": ["coding", "programming", "specification", "AI"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 87
    },
    {
      "id": "faq-007",
      "category": "Getting Started",
      "question": "What will I be able to do after completing this course?",
      "answer": "Graduates can produce MicroSims supporting learning objectives, evaluate simulations using research-based criteria, adapt complexity for any audience, collaborate with AI tools, build reusable simulation libraries, apply universal design principles, and conduct user testing with iteration.",
      "bloom_level": "Understand",
      "difficulty": "easy",
      "concepts": ["Learning Outcome", "MicroSim", "Evaluation Rubric"],
      "keywords": ["outcomes", "skills", "graduates", "abilities"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 68
    },
    {
      "id": "faq-008",
      "category": "Getting Started",
      "question": "What is a MicroSim?",
      "answer": "A MicroSim (Micro Simulation) is a small, focused interactive simulation designed to teach a specific concept or skill through exploration and visualization. Unlike comprehensive simulations, MicroSims target atomic concepts that can be understood in 5-15 minutes of interaction.",
      "bloom_level": "Understand",
      "difficulty": "easy",
      "concepts": ["MicroSim", "Interactive Simulation", "Atomic Concepts"],
      "keywords": ["MicroSim", "simulation", "interactive", "definition"],
      "source_links": ["docs/glossary.md#microsim"],
      "has_example": true,
      "word_count": 72
    },
    {
      "id": "faq-009",
      "category": "Getting Started",
      "question": "What makes a learning objective simulation-ready?",
      "answer": "Simulation-ready objectives involve dynamic relationships changing over time, multiple interacting variables, abstract concepts benefiting from visualization, cause-effect relationships for exploration, and common misconceptions that can be revealed. Objectives focused on factual recall may be better served by other methods.",
      "bloom_level": "Analyze",
      "difficulty": "medium",
      "concepts": ["Simulation Readiness", "Learning Objective", "Concept Characteristics"],
      "keywords": ["simulation-ready", "objectives", "criteria", "dynamic"],
      "source_links": ["docs/chapters/01-foundations-learning-objective-analysis/index.md"],
      "has_example": false,
      "word_count": 82
    },
    {
      "id": "faq-010",
      "category": "Getting Started",
      "question": "Can I use MicroSims I create in my own courses?",
      "answer": "Yes. All MicroSims you create during this course are yours to use in your teaching. The course teaches deployment to LMS systems, embedding in course materials, and sharing with educators under appropriate licenses.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Content Sharing", "LMS Integration", "Reusability"],
      "keywords": ["ownership", "courses", "teaching", "sharing"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-011",
      "category": "Getting Started",
      "question": "How do I access the course materials?",
      "answer": "The course is delivered as an intelligent textbook at https://dmccreary.github.io/automating-instructional-design/. All 12 modules, practice activities, and example MicroSims are freely accessible. Claude Code access is needed for hands-on generation activities.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Intelligent Textbook", "Educational Technology"],
      "keywords": ["access", "materials", "textbook", "online"],
      "source_links": ["docs/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-012",
      "category": "Core Concepts",
      "question": "What is Bloom's Taxonomy and why does it matter?",
      "answer": "Bloom's Taxonomy is a hierarchical classification of cognitive complexity with six levels: Remember, Understand, Apply, Analyze, Evaluate, Create. It matters for MicroSim design because different cognitive levels require different interaction types.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Bloom's Taxonomy", "Cognitive Complexity", "Remember Level", "Understand Level", "Apply Level", "Analyze Level", "Evaluate Level", "Create Level"],
      "keywords": ["Bloom", "taxonomy", "cognitive", "levels"],
      "source_links": ["docs/chapters/01-foundations-learning-objective-analysis/index.md", "docs/glossary.md#blooms-taxonomy"],
      "has_example": true,
      "word_count": 89
    },
    {
      "id": "faq-013",
      "category": "Core Concepts",
      "question": "How do I decompose compound learning objectives?",
      "answer": "Identify action verbs (each represents a separate skill), list prerequisite concepts, map dependencies, and create atomic objectives with one measurable skill per statement. Compound objectives should be broken into components for effective instruction.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Objective Decomposition", "Compound Objectives", "Atomic Concepts", "Concept Dependencies"],
      "keywords": ["decompose", "objectives", "compound", "atomic"],
      "source_links": ["docs/chapters/01-foundations-learning-objective-analysis/index.md"],
      "has_example": true,
      "word_count": 76
    },
    {
      "id": "faq-014",
      "category": "Core Concepts",
      "question": "What are the main visualization paradigms for MicroSims?",
      "answer": "Seven primary paradigms: Animation (p5.js) for motion and physics; Network (vis-network) for relationships; Timeline (vis-timeline) for sequences; Chart (Chart.js, Plotly) for comparisons; Map (Leaflet) for geography; Diagram (Mermaid) for flowcharts; Set (Venn.js) for classification.",
      "bloom_level": "Remember",
      "difficulty": "medium",
      "concepts": ["Visualization Paradigm", "p5.js Animation", "Network Graph", "Timeline Visualization", "Chart Visualization", "Map Visualization", "Diagram Visualization", "Venn Diagram"],
      "keywords": ["visualization", "paradigms", "libraries", "types"],
      "source_links": ["docs/chapters/03-microsim-pattern-library/index.md"],
      "has_example": false,
      "word_count": 72
    },
    {
      "id": "faq-015",
      "category": "Core Concepts",
      "question": "What is Cognitive Load Theory?",
      "answer": "Cognitive Load Theory explains how instruction demands affect learning based on working memory limitations. Three types: intrinsic (inherent complexity), extraneous (wasted effort from poor design), germane (productive schema-building). Good design minimizes extraneous while maximizing germane load.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Cognitive Load Theory", "Intrinsic Load", "Extraneous Load", "Germane Load", "Working Memory"],
      "keywords": ["cognitive load", "intrinsic", "extraneous", "germane"],
      "source_links": ["docs/chapters/07-cognitive-load-visual-design/index.md", "docs/glossary.md#cognitive-load-theory"],
      "has_example": true,
      "word_count": 78
    },
    {
      "id": "faq-016",
      "category": "Core Concepts",
      "question": "What is the split attention effect?",
      "answer": "The split attention effect occurs when learners must mentally integrate information from physically or temporally separated sources, increasing cognitive load. In MicroSims, avoid placing labels in legends instead of on elements, or separating instructions from actions.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Split Attention Effect", "Extraneous Load", "Cognitive Load Theory"],
      "keywords": ["split attention", "cognitive load", "integration"],
      "source_links": ["docs/chapters/07-cognitive-load-visual-design/index.md"],
      "has_example": false,
      "word_count": 68
    },
    {
      "id": "faq-017",
      "category": "Core Concepts",
      "question": "What is a learning graph?",
      "answer": "A learning graph is a directed graph where nodes represent concepts and edges represent prerequisite dependencies. It helps sequence content, identify prerequisite gaps, find bottleneck concepts, and create personalized learning paths. The course's graph contains 200 concepts.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Learning Pathway", "Concept Dependencies", "Prerequisite Knowledge"],
      "keywords": ["learning graph", "dependencies", "prerequisites", "concepts"],
      "source_links": ["docs/learning-graph/index.md"],
      "has_example": false,
      "word_count": 62
    },
    {
      "id": "faq-018",
      "category": "Core Concepts",
      "question": "How does progressive disclosure work in MicroSims?",
      "answer": "Progressive disclosure reveals complexity gradually. Start with simple defaults, offer advanced options toggle, unlock features after mastery, use layered interfaces. This reduces initial cognitive load while allowing access to advanced features when ready.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Progressive Disclosure", "Scaffolded Complexity", "Cognitive Load Theory"],
      "keywords": ["progressive disclosure", "complexity", "gradual", "layered"],
      "source_links": ["docs/chapters/07-cognitive-load-visual-design/index.md"],
      "has_example": true,
      "word_count": 67
    },
    {
      "id": "faq-019",
      "category": "Core Concepts",
      "question": "What is the difference between intrinsic and extraneous cognitive load?",
      "answer": "Intrinsic load is determined by material complexity and can't be eliminated. Extraneous load is caused by poor design and should be minimized. Intrinsic is managed through sequencing; extraneous is eliminated through better design.",
      "bloom_level": "Analyze",
      "difficulty": "medium",
      "concepts": ["Intrinsic Load", "Extraneous Load", "Cognitive Load Theory"],
      "keywords": ["intrinsic", "extraneous", "cognitive load", "difference"],
      "source_links": ["docs/glossary.md#intrinsic-load", "docs/glossary.md#extraneous-load"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-020",
      "category": "Core Concepts",
      "question": "What are action verbs and why are they important?",
      "answer": "Action verbs describe observable, measurable behaviors demonstrating learning. They make objectives assessable, align with Bloom's levels, and guide activity design. Strong verbs: calculate, compare, design. Weak verbs: understand, appreciate, know.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Action Verbs", "Measurable Outcomes", "Learning Objective"],
      "keywords": ["action verbs", "measurable", "observable", "Bloom"],
      "source_links": ["docs/glossary.md#action-verbs"],
      "has_example": true,
      "word_count": 62
    },
    {
      "id": "faq-021",
      "category": "Core Concepts",
      "question": "How do misconceptions affect MicroSim design?",
      "answer": "Misconceptions can be inadvertently reinforced or intentionally corrected by simulations. Well-designed MicroSims include edge cases where intuition fails, prediction prompts to reveal thinking, and contrasts between correct and incorrect models.",
      "bloom_level": "Analyze",
      "difficulty": "hard",
      "concepts": ["Misconception", "Common Misconceptions", "Misconception Correction", "Misconception Reinforcement", "Prediction Prompt"],
      "keywords": ["misconceptions", "correction", "prediction", "intuition"],
      "source_links": ["docs/chapters/08-anticipating-misconceptions/index.md"],
      "has_example": true,
      "word_count": 68
    },
    {
      "id": "faq-022",
      "category": "Core Concepts",
      "question": "What is a specification document?",
      "answer": "A specification document is a detailed description of what a MicroSim should contain, how it should behave, and what it should teach. It includes learning objective, visual layout, interactions, parameters, edge cases, and success criteria.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Specification Document", "Visual Description", "Interaction Behavior", "Success Criteria"],
      "keywords": ["specification", "document", "blueprint", "description"],
      "source_links": ["docs/chapters/05-writing-microsim-specifications/index.md"],
      "has_example": false,
      "word_count": 64
    },
    {
      "id": "faq-023",
      "category": "Core Concepts",
      "question": "What is intent preservation in AI-assisted design?",
      "answer": "Intent preservation ensures pedagogical purpose survives translation from specification to generated output. Be specific, include examples, specify what should NOT happen, review against objectives, and iterate with refinement prompts.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Intent Preservation", "Specification Ambiguity", "AI Interpretation"],
      "keywords": ["intent", "preservation", "translation", "AI"],
      "source_links": ["docs/chapters/09-generating-microsims-ai-tools/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-024",
      "category": "Core Concepts",
      "question": "How do I identify concepts that are simulation-ready?",
      "answer": "Simulation-ready concepts have: dynamic behavior (change/process), controllable variables, observable outcomes, exploration value, and misconception potential. Not simulation-ready: memorizing vocabulary, fixed procedures, static facts.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Simulation Readiness", "Concept Characteristics", "Dynamic Systems"],
      "keywords": ["simulation-ready", "dynamic", "controllable", "observable"],
      "source_links": ["docs/chapters/01-foundations-learning-objective-analysis/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-025",
      "category": "Core Concepts",
      "question": "What is the difference between formative and summative assessment?",
      "answer": "Formative assessment occurs during learning to provide feedback (journals, peer feedback, self-evaluation). Summative assessment evaluates at the end (portfolio project). MicroSims can support both through embedded feedback and data collection.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["Evaluation Rubric", "Peer Feedback", "Self-Evaluation"],
      "keywords": ["formative", "summative", "assessment", "feedback"],
      "source_links": ["docs/course-description.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-026",
      "category": "Technical Details",
      "question": "What JavaScript libraries are used for MicroSims?",
      "answer": "Seven libraries: p5.js (animations), vis-network (graphs), vis-timeline (timelines), Chart.js (standard charts), Plotly (advanced charts), Leaflet (maps), Mermaid (diagrams from text). You don't code these—AI generates appropriate code.",
      "bloom_level": "Remember",
      "difficulty": "medium",
      "concepts": ["p5.js Animation", "vis-network Library", "vis-timeline Library", "Chart.js Library", "Plotly Library", "Leaflet Library", "Mermaid Library"],
      "keywords": ["JavaScript", "libraries", "p5.js", "Chart.js"],
      "source_links": ["docs/chapters/04-visualization-libraries-tools/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-027",
      "category": "Technical Details",
      "question": "How do I choose between Chart.js and Plotly?",
      "answer": "Chart.js: standard chart types, clean defaults, general audiences. Plotly: 3D visualizations, publication quality, advanced interactivity, technical audiences. For most educational contexts, Chart.js is sufficient and simpler.",
      "bloom_level": "Evaluate",
      "difficulty": "medium",
      "concepts": ["Chart.js Library", "Plotly Library", "Chart Visualization"],
      "keywords": ["Chart.js", "Plotly", "choose", "comparison"],
      "source_links": ["docs/chapters/04-visualization-libraries-tools/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-028",
      "category": "Technical Details",
      "question": "What makes p5.js good for educational animations?",
      "answer": "p5.js offers immediate mode rendering, simple coordinate system, built-in physics helpers, interactive input handling, and clear setup/draw pattern. Excellent for projectile motion, wave interference, particle systems, algorithm visualization.",
      "bloom_level": "Understand",
      "difficulty": "medium",
      "concepts": ["p5.js Animation", "Motion Simulation", "Physics Simulation"],
      "keywords": ["p5.js", "animation", "physics", "interactive"],
      "source_links": ["docs/chapters/04-visualization-libraries-tools/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-029",
      "category": "Technical Details",
      "question": "When should I use vis-network vs. Mermaid for diagrams?",
      "answer": "vis-network: interactive graphs (drag, zoom), dynamic structures, physics layouts, relationship focus. Mermaid: static export, standard patterns (flowchart, sequence), text-based source, quick prototyping.",
      "bloom_level": "Evaluate",
      "difficulty": "medium",
      "concepts": ["vis-network Library", "Mermaid Library", "Network Graph", "Diagram Visualization"],
      "keywords": ["vis-network", "Mermaid", "diagrams", "interactive"],
      "source_links": ["docs/chapters/04-visualization-libraries-tools/index.md"],
      "has_example": false,
      "word_count": 48
    },
    {
      "id": "faq-030",
      "category": "Technical Details",
      "question": "How do I make MicroSims responsive to different screen sizes?",
      "answer": "Use relative sizing (percentages, viewport units), call updateCanvasSize() first in p5.js setup(), test at multiple sizes, simplify on small screens, and respect aspect ratios. The generator handles most responsiveness automatically.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Responsiveness Testing", "Touch Target Size"],
      "keywords": ["responsive", "screen", "mobile", "sizing"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-031",
      "category": "Technical Details",
      "question": "What is the structure of a MicroSim file package?",
      "answer": "Each MicroSim contains: index.md (MkDocs page), main.html (standalone file), [sim-name].js (JavaScript), and local.css (scoped styles). The index.md embeds via iframe; main.html works standalone.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["Documentation Standard", "Template Library"],
      "keywords": ["structure", "files", "package", "folder"],
      "source_links": ["CLAUDE.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-032",
      "category": "Technical Details",
      "question": "How do I embed a MicroSim in MkDocs?",
      "answer": "Add an iframe to markdown: <iframe src='./main.html' width='100%' height='450px' scrolling='no'></iframe>. Never use style attributes on iframes. Use relative paths. Test at the full local URL including repository name.",
      "bloom_level": "Apply",
      "difficulty": "easy",
      "concepts": ["LMS Integration", "Intelligent Textbook"],
      "keywords": ["embed", "MkDocs", "iframe", "markdown"],
      "source_links": ["CLAUDE.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-033",
      "category": "Technical Details",
      "question": "What file formats does the MicroSim generator produce?",
      "answer": "The generator produces: HTML (standalone with embedded CSS/JS), JavaScript (separate .js file), CSS (scoped local.css), Markdown (index.md for MkDocs), and optional metadata JSON with learning objectives and parameters.",
      "bloom_level": "Remember",
      "difficulty": "easy",
      "concepts": ["MicroSim Generator", "Code Generation"],
      "keywords": ["formats", "output", "HTML", "JavaScript"],
      "source_links": ["docs/chapters/09-generating-microsims-ai-tools/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-034",
      "category": "Technical Details",
      "question": "How do I test MicroSims locally?",
      "answer": "Run 'mkdocs serve' and access at http://127.0.0.1:8000/automating-instructional-design/. Navigate to your simulation's page. Use browser developer tools (F12) to debug JavaScript issues.",
      "bloom_level": "Apply",
      "difficulty": "easy",
      "concepts": ["Functionality Testing", "Bug Identification"],
      "keywords": ["test", "local", "mkdocs", "serve"],
      "source_links": ["CLAUDE.md"],
      "has_example": false,
      "word_count": 46
    },
    {
      "id": "faq-035",
      "category": "Technical Details",
      "question": "What is version control for MicroSims?",
      "answer": "Version control tracks changes over time, enabling history review, rollback, collaboration, and documentation. While the course doesn't teach Git in detail, it introduces concepts for maintaining MicroSim libraries.",
      "bloom_level": "Understand",
      "difficulty": "easy",
      "concepts": ["Version Control", "Iteration Management", "Change Log"],
      "keywords": ["version control", "history", "rollback", "Git"],
      "source_links": ["docs/chapters/10-quality-evaluation-frameworks/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-036",
      "category": "Common Challenges",
      "question": "My specification is producing unexpected results. What should I check?",
      "answer": "Check for: ambiguity ('interactive' vs specific controls), missing defaults, undefined edge cases, implicit assumptions (colors, units), conflicting requirements. Write specifications as if explaining to someone unfamiliar with your subject.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Specification Ambiguity", "Edge Case Definition", "Intent Preservation"],
      "keywords": ["specification", "unexpected", "ambiguity", "troubleshoot"],
      "source_links": ["docs/chapters/05-writing-microsim-specifications/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-037",
      "category": "Common Challenges",
      "question": "The generated MicroSim doesn't match my learning objective. How do I fix this?",
      "answer": "Check: objective clarity (specific and measurable?), interaction match (teaches the skill?), cognitive level (right thinking required?), feedback presence (learner knows success?). Use refinement prompts to adjust.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Objective Alignment", "Pedagogical Evaluation", "Refinement Prompt"],
      "keywords": ["mismatch", "objective", "alignment", "fix"],
      "source_links": ["docs/chapters/10-quality-evaluation-frameworks/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-038",
      "category": "Common Challenges",
      "question": "My MicroSim works on desktop but not mobile. What's wrong?",
      "answer": "Common issues: touch targets too small (need 44x44px minimum), hover-dependent features, fixed pixel sizes, landscape assumptions, performance lag. Test early on mobile. Specify mobile requirements in specifications.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Touch Target Size", "Responsiveness Testing", "Functionality Testing"],
      "keywords": ["mobile", "desktop", "responsive", "touch"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-039",
      "category": "Common Challenges",
      "question": "Learners are confused by my MicroSim. How do I simplify it?",
      "answer": "Signs of overload: learners don't know where to start, miss features, make random changes, give up. Solutions: reduce visible controls (progressive disclosure), add guided scenarios, increase contrast, remove decorative elements, add explicit instructions.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Extraneous Load", "Progressive Disclosure", "Visual Simplicity", "Guided Exploration"],
      "keywords": ["confused", "simplify", "overload", "clarity"],
      "source_links": ["docs/chapters/07-cognitive-load-visual-design/index.md"],
      "has_example": false,
      "word_count": 62
    },
    {
      "id": "faq-040",
      "category": "Common Challenges",
      "question": "My MicroSim reinforces a misconception instead of correcting it. What happened?",
      "answer": "Reinforcement occurs when: simulation only shows expected cases, edge cases are missing, predictions aren't contradicted, visualization matches misconception. Add prediction prompts, edge cases, and explicit model contrasts.",
      "bloom_level": "Analyze",
      "difficulty": "hard",
      "concepts": ["Misconception Reinforcement", "Prediction Prompt", "Conceptual Boundary"],
      "keywords": ["misconception", "reinforcing", "correction", "design"],
      "source_links": ["docs/chapters/08-anticipating-misconceptions/index.md"],
      "has_example": true,
      "word_count": 58
    },
    {
      "id": "faq-041",
      "category": "Common Challenges",
      "question": "The AI keeps generating similar but incorrect code. How do I break the pattern?",
      "answer": "Change approach (describe differently), provide examples (show correct behavior), be more specific (add constraints), start fresh (regenerate completely), or make manual adjustments for small fixes.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Regeneration Decision", "Refinement Prompt", "Manual Adjustment"],
      "keywords": ["pattern", "incorrect", "regenerate", "iteration"],
      "source_links": ["docs/chapters/09-generating-microsims-ai-tools/index.md"],
      "has_example": true,
      "word_count": 52
    },
    {
      "id": "faq-042",
      "category": "Common Challenges",
      "question": "How do I handle parameter edge cases?",
      "answer": "Common issues: division by zero, negative values where only positive make sense, scale-breaking values, undefined combinations. Explicitly define boundary behavior in specifications: 'When temperature reaches 0C, display ice formation.'",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Edge Case Definition", "Behavior Constraints", "Parameter Space"],
      "keywords": ["edge cases", "parameters", "boundary", "limits"],
      "source_links": ["docs/chapters/05-writing-microsim-specifications/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-043",
      "category": "Common Challenges",
      "question": "My MicroSim is too slow. How do I improve performance?",
      "answer": "Issues: too many animated elements, unnecessary redraws, large images, complex per-frame calculations. Solutions: reduce counts, redraw only on changes, compress images, cache values. Specify constraints: 'maintain 30fps on mobile.'",
      "bloom_level": "Apply",
      "difficulty": "hard",
      "concepts": ["Animation Speed", "Technical Evaluation"],
      "keywords": ["slow", "performance", "speed", "optimize"],
      "source_links": ["docs/chapters/10-quality-evaluation-frameworks/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-044",
      "category": "Best Practices",
      "question": "How do I write effective MicroSim specifications?",
      "answer": "Include: clear learning objective (specific, measurable), target audience, visual description (layout, colors, sizes), interaction behaviors, parameter ranges (min, max, default), success criteria, and edge cases. Template: 'Create a MicroSim that demonstrates [concept] for [audience]...'",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Specification Document", "Visual Description", "Interaction Behavior", "Success Criteria"],
      "keywords": ["specification", "effective", "writing", "template"],
      "source_links": ["docs/chapters/05-writing-microsim-specifications/index.md"],
      "has_example": false,
      "word_count": 72
    },
    {
      "id": "faq-045",
      "category": "Best Practices",
      "question": "What's the right level of complexity for different audiences?",
      "answer": "Early Childhood: large targets, 1-2 controls. Elementary: guided, 2-3 controls. Middle School: multiple variables, hypothesis testing. High School: real-world data, edge cases. Undergraduate: theoretical, mathematical. Graduate: research, parameter exploration. Corporate: job-relevant, time-efficient.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Early Childhood Design", "Elementary Design", "Middle School Design", "High School Design", "Undergraduate Design", "Graduate Design"],
      "keywords": ["complexity", "audience", "age", "level"],
      "source_links": ["docs/chapters/06-adapting-audience-levels/index.md"],
      "has_example": false,
      "word_count": 62
    },
    {
      "id": "faq-046",
      "category": "Best Practices",
      "question": "How do I balance engagement and learning?",
      "answer": "Good engagement: interactive elements revealing concepts, immediate feedback, relevant scenarios, appropriate challenge. Bad engagement: decorative animations, game elements overshadowing learning, complexity for its own sake, entertaining but not teaching.",
      "bloom_level": "Evaluate",
      "difficulty": "medium",
      "concepts": ["Engagement Balance", "Extraneous Load", "Learner Control"],
      "keywords": ["engagement", "balance", "distraction", "learning"],
      "source_links": ["docs/chapters/07-cognitive-load-visual-design/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-047",
      "category": "Best Practices",
      "question": "When should I use prediction prompts?",
      "answer": "Use when: common misconceptions exist, intuition often fails, correct answer is surprising, predictions activate prior knowledge, you want to reveal learner thinking. Implementation: pause before running, ask for prediction, then compare with results.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Prediction Prompt", "Misconception Correction", "Hypothesis Testing"],
      "keywords": ["prediction", "prompts", "misconception", "reveal"],
      "source_links": ["docs/chapters/08-anticipating-misconceptions/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-048",
      "category": "Best Practices",
      "question": "How do I design for accessibility?",
      "answer": "Ensure: screen reader support (semantic HTML, alt text, ARIA), keyboard navigation, color independence (don't rely solely on color), reduced motion respect, sufficient contrast (4.5:1 for text), adequate touch targets (44x44px minimum).",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Screen Reader Support", "Keyboard Navigation", "Color Accessibility", "Reduced Motion", "Contrast Design", "Touch Target Size"],
      "keywords": ["accessibility", "screen reader", "keyboard", "contrast"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 62
    },
    {
      "id": "faq-049",
      "category": "Best Practices",
      "question": "How do I evaluate if a MicroSim is effective?",
      "answer": "Three-lens model: Technical (works without errors, responsive, no bugs), Pedagogical (targets objective, appropriate cognitive level, supports understanding), User Experience (intuitive, accessible, appropriate engagement). Create rubrics covering all three.",
      "bloom_level": "Evaluate",
      "difficulty": "medium",
      "concepts": ["Technical Evaluation", "Pedagogical Evaluation", "UX Evaluation", "Evaluation Rubric"],
      "keywords": ["evaluate", "effective", "rubric", "three-lens"],
      "source_links": ["docs/chapters/10-quality-evaluation-frameworks/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-050",
      "category": "Best Practices",
      "question": "What makes a good user testing session?",
      "answer": "Include: clear goals (questions to answer), representative users (target audience), think-aloud protocol (verbalize thoughts), observation focus (watch actions), non-leading questions, ethical considerations (consent, especially with minors).",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Think-Aloud Protocol", "Observation Technique", "Learner Feedback", "Ethical Research"],
      "keywords": ["user testing", "think-aloud", "observation", "feedback"],
      "source_links": ["docs/chapters/11-user-testing-iteration/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-051",
      "category": "Best Practices",
      "question": "How do I prioritize changes after user testing?",
      "answer": "Categorize: Critical (blocks learning, fix immediately), High (confuses most users, fix before release), Medium (affects some users, next iteration), Low (nice to have, defer). Focus on patterns across multiple users rather than individual preferences.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Change Prioritization", "Critical Changes", "Nice-to-Have Changes", "Test Interpretation"],
      "keywords": ["prioritize", "changes", "testing", "critical"],
      "source_links": ["docs/chapters/11-user-testing-iteration/index.md"],
      "has_example": false,
      "word_count": 58
    },
    {
      "id": "faq-052",
      "category": "Best Practices",
      "question": "How do I maintain MicroSims over time?",
      "answer": "Planning includes: regular testing (quarterly functionality checks), library updates (JavaScript versions), content currency (update data/examples), feedback monitoring (user reports), documentation (record changes), backup (version control and storage).",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Maintenance Planning", "Version Control", "Change Log", "Documentation Standard"],
      "keywords": ["maintain", "updates", "long-term", "planning"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-053",
      "category": "Advanced Topics",
      "question": "How do I create MicroSims that adapt to learner performance?",
      "answer": "Track performance (correct/incorrect), define difficulty levels, set thresholds for adjustment, provide feedback about changes, allow learner override. Example: start with simple problems, increase difficulty after successes, return to simpler with hints after errors.",
      "bloom_level": "Create",
      "difficulty": "hard",
      "concepts": ["Differentiation Strategy", "Scaffolded Complexity", "Learner Feedback"],
      "keywords": ["adaptive", "performance", "difficulty", "personalized"],
      "source_links": ["docs/chapters/06-adapting-audience-levels/index.md"],
      "has_example": true,
      "word_count": 62
    },
    {
      "id": "faq-054",
      "category": "Advanced Topics",
      "question": "How can I use MicroSims for assessment?",
      "answer": "Support assessment through: embedded questions (predict-then-test), performance tracking (log choices and outcomes), time-on-task measurement, path analysis (sequence followed), final state capture. LMS integration enables grade reporting and analytics.",
      "bloom_level": "Apply",
      "difficulty": "hard",
      "concepts": ["Learning Analytics", "Interaction Tracking", "LMS Integration"],
      "keywords": ["assessment", "tracking", "analytics", "grading"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-055",
      "category": "Advanced Topics",
      "question": "How do I design for multiple learning modalities?",
      "answer": "UDL suggests multiple means of: Engagement (choice, relevance, self-regulation), Representation (visual/auditory/text, vocabulary support, pattern highlighting), Action/Expression (multiple interaction ways, scaffolding, multiformat feedback).",
      "bloom_level": "Apply",
      "difficulty": "hard",
      "concepts": ["UDL Principles", "Universal Design", "Differentiation Strategy"],
      "keywords": ["modalities", "UDL", "multiple", "representation"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-056",
      "category": "Advanced Topics",
      "question": "How do I integrate MicroSims with learning management systems?",
      "answer": "Options: embedding (iframe in LMS pages), LTI (deeper integration), xAPI (detailed activity tracking), SCORM (legacy completion tracking). For most uses, simple embedding with manual completion marking is sufficient.",
      "bloom_level": "Apply",
      "difficulty": "hard",
      "concepts": ["LMS Integration", "Interaction Tracking", "Learning Analytics"],
      "keywords": ["LMS", "integration", "LTI", "SCORM"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 56
    },
    {
      "id": "faq-057",
      "category": "Advanced Topics",
      "question": "How do I handle localization and translation?",
      "answer": "Strategies: separate content from code (JSON data files), design for text expansion (other languages may be longer), use icons alongside text, consider reading direction (RTL), test with native speakers.",
      "bloom_level": "Apply",
      "difficulty": "hard",
      "concepts": ["Multilingual Support", "Cultural Sensitivity", "Vocabulary Level"],
      "keywords": ["localization", "translation", "multilingual", "international"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-058",
      "category": "Advanced Topics",
      "question": "How do I create a MicroSim library for my organization?",
      "answer": "Establish standards (consistent structure, documentation), create templates (starting points), build catalog (searchable index), define workflows (review, approval), enable sharing (licensing), and track usage (analytics).",
      "bloom_level": "Create",
      "difficulty": "hard",
      "concepts": ["Library Organization", "Template Library", "Content Sharing", "Educator Collaboration"],
      "keywords": ["library", "organization", "catalog", "standards"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-059",
      "category": "Advanced Topics",
      "question": "What emerging technologies might affect MicroSim design?",
      "answer": "Future considerations: more sophisticated AI generation, voice interfaces, AR/VR immersive simulations, haptic feedback on mobile, real-time collaboration. The course provides transferable pedagogical foundations regardless of specific technologies.",
      "bloom_level": "Analyze",
      "difficulty": "hard",
      "concepts": ["AI-Assisted Design", "Educational Technology"],
      "keywords": ["emerging", "future", "AI", "VR", "AR"],
      "source_links": ["docs/chapters/09-generating-microsims-ai-tools/index.md"],
      "has_example": false,
      "word_count": 52
    },
    {
      "id": "faq-060",
      "category": "Advanced Topics",
      "question": "How do I contribute MicroSims to the community?",
      "answer": "Document thoroughly (objectives, instructions), choose license (Creative Commons), test accessibility, publish openly (GitHub, repositories), respond to feedback and maintain shared resources.",
      "bloom_level": "Apply",
      "difficulty": "medium",
      "concepts": ["Content Sharing", "Educator Collaboration", "Documentation Standard"],
      "keywords": ["contribute", "community", "sharing", "open"],
      "source_links": ["docs/chapters/12-accessibility-deployment-completion/index.md"],
      "has_example": false,
      "word_count": 48
    }
  ]
}
